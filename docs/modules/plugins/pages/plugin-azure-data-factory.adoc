:azure-service-name: data-factory

= Azure Data Factory Plugin

The plugin provides functionality to interact with https://docs.microsoft.com/en-us/azure/data-factory/[Azure Data Factory]

== Installation

.build.gradle
[source,gradle,subs="attributes+"]
----
implementation(group: 'org.vividus', name: 'vividus-plugin-azure-data-factory', version: '{current-version}')
----

== Configuration

include::partial$azure-authentication.adoc[]

include::partial$azure-profile-and-subscription.adoc[]

== Steps

=== Run Pipeline with expected status

Creates a run of a pipeline in Data Factory, waits for its completion or until
the timeout is reached and validates the run status is equal to the expected one.

[source,gherkin]
----
When I run pipeline `$pipelineName` in Data Factory `$factoryName` from resource group `$resourceGroupName` with wait timeout `$waitTimeout` and expect run status to be equal to `$expectedPipelineRunStatus`
----

* `$pipelineName` - The name of the pipeline to run.
* `$factoryName` - The name of the factory.
* `$resourceGroupName` - The name of the resource group of the factory.
* `$waitTimeout` - The maximum duration of time to wait for the pipeline completion in {iso-date-format-link} format.
* `$expectedPipelineRunStatus` - The expected pipeline run status, e.g. `Succeeded`.

.Run pipeline
[source,gherkin]
----
When I run pipeline `vividus-pipeline` in Data Factory `vividus-data-factory` from resource group `vividus-resource-group-ingestion` with wait timeout `PT30S` and expect run status to be equal to `Succeeded`
----

=== Collect pipeline runs

Collects pipeline runs in Data factory based on input filter conditions.

[source,gherkin]
----
When I collect runs of pipeline `$pipelineName` filtered by:$filters in Data Factory `$factoryName` from resource group `$resourceGroupName` and save them as JSON to $scopes variable `$variableName`
----

* `$pipelineName` - The name of the pipeline to find runs.
* `$filters` - The ExamplesTable with filters to be applied to the pipeline runs to limit the resulting set.
+
.The supported filter types
[cols="1,1,2", options="header"]
|===
|Type
|Alias
|Description

|`LAST_UPDATED_AFTER`
|`last updated after`
|The time at or after which the run event was updated in {iso-date-format-link} format.

|`LAST_UPDATED_BEFORE`
|`last updated before`
|The time at or before which the run event was updated in {iso-date-format-link} format.

|===
+
The filters can be combined in any order and in any composition.
+
.The combination of filters
[source,gherkin]
----
|filterType         |filterValue              |
|last updated after |2021-11-15T00:00:00+03:00|
|last updated before|2021-11-15T00:00:00+03:00|
----

* `$factoryName` - The name of the factory.
* `$resourceGroupName` - The name of the resource group of the factory.
* `$scopes` - xref:commons:variables.adoc#_scopes[The comma-separated set of the variables scopes].
* `$variableName` - The variable name to store the pipeline runs in JSON format.

[IMPORTANT]
====
The client should have permission to run action `Microsoft.DataFactory/factories/pipelineruns/read`
over scope `/subscriptions/{subscription ID}/resourceGroups/{resource group name}/providers/Microsoft.DataFactory`.
====

.Find pipeline runs from the last day
[source,gherkin]
----
When I collect runs of pipeline `vividus-pipeline` filtered by:
|filterType          |filterValue                                      |
|LAST_UPDATED_AFTER  |#{generateDate(-P1D, yyyy-MM-dd'T'HH:mm:ssXXX)} |
|LAST_UPDATED_BEFORE |#{generateDate(P, yyyy-MM-dd'T'HH:mm:ssXXX)}    |
in Data Factory `vividus-data-factory` from resource group `vividus-resource-group-ingestion` and save them as JSON to scenario variable `pipeline-runs`
----
